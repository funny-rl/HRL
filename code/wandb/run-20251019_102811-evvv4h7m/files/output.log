Training steps: 201 Episode Num: 1 Episode T: 200 Reward: -1591.648
Training steps: 401 Episode Num: 2 Episode T: 200 Reward: -1323.079
Training steps: 601 Episode Num: 3 Episode T: 200 Reward: -866.169
Training steps: 801 Episode Num: 4 Episode T: 200 Reward: -912.444
Training steps: 1001 Episode Num: 5 Episode T: 200 Reward: -1168.470
Training steps: 1201 Episode Num: 6 Episode T: 200 Reward: -1706.643
Training steps: 1401 Episode Num: 7 Episode T: 200 Reward: -1438.148
Training steps: 1601 Episode Num: 8 Episode T: 200 Reward: -1700.081
Training steps: 1801 Episode Num: 9 Episode T: 200 Reward: -1771.222
Traceback (most recent call last):
  File "/gpfs/home1/aiphw227/HRL/code/main.py", line 172, in <module>
    main()
  File "/home1/aiphw227/miniconda3/envs/rl/lib/python3.11/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/home1/aiphw227/miniconda3/envs/rl/lib/python3.11/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/home1/aiphw227/miniconda3/envs/rl/lib/python3.11/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/home1/aiphw227/miniconda3/envs/rl/lib/python3.11/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           ^^^^^^
  File "/home1/aiphw227/miniconda3/envs/rl/lib/python3.11/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            ^^^^^^^^^^
  File "/home1/aiphw227/miniconda3/envs/rl/lib/python3.11/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          ^^^^^^^^
  File "/home1/aiphw227/miniconda3/envs/rl/lib/python3.11/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
                       ^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home1/aiphw227/HRL/code/main.py", line 156, in main
    avg_reward, avg_steps = eval(
                            ^^^^^
  File "/gpfs/home1/aiphw227/HRL/code/main.py", line 28, in eval
    next_state, reward, terminated, truncated, _ = eval_env.step(action)
                                                   ^^^^^^^^^^^^^^^^^^^^^
  File "/home1/aiphw227/miniconda3/envs/rl/lib/python3.11/site-packages/gymnasium/wrappers/common.py", line 125, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "/home1/aiphw227/miniconda3/envs/rl/lib/python3.11/site-packages/gymnasium/wrappers/common.py", line 393, in step
    return super().step(action)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home1/aiphw227/miniconda3/envs/rl/lib/python3.11/site-packages/gymnasium/core.py", line 322, in step
    return self.env.step(action)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home1/aiphw227/miniconda3/envs/rl/lib/python3.11/site-packages/gymnasium/wrappers/common.py", line 285, in step
    return self.env.step(action)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home1/aiphw227/miniconda3/envs/rl/lib/python3.11/site-packages/gymnasium/envs/classic_control/pendulum.py", line 140, in step
    newthdot = thdot + (3 * g / (2 * l) * np.sin(th) + 3.0 / (m * l**2) * u) * dt
                                          ^^^^^^^^^^
KeyboardInterrupt
