Training steps: 201 Episode Num: 1 Episode T: 200 Reward: -1758.686
Training steps: 401 Episode Num: 2 Episode T: 200 Reward: -1302.175
Training steps: 601 Episode Num: 3 Episode T: 200 Reward: -932.801
Training steps: 801 Episode Num: 4 Episode T: 200 Reward: -892.284
Training steps: 1001 Episode Num: 5 Episode T: 200 Reward: -1114.681
Training steps: 1201 Episode Num: 6 Episode T: 200 Reward: -1732.823
Training steps: 1401 Episode Num: 7 Episode T: 200 Reward: -1515.181
Training steps: 1601 Episode Num: 8 Episode T: 200 Reward: -1663.384
Training steps: 1801 Episode Num: 9 Episode T: 200 Reward: -1716.366
Training steps: 2001 Episode Num: 10 Episode T: 200 Reward: -1918.526
Training steps: 2201 Episode Num: 11 Episode T: 200 Reward: -1764.786
Training steps: 2401 Episode Num: 12 Episode T: 200 Reward: -1511.127
Training steps: 2601 Episode Num: 13 Episode T: 200 Reward: -1531.800
Training steps: 2801 Episode Num: 14 Episode T: 200 Reward: -1457.000
Training steps: 3001 Episode Num: 15 Episode T: 200 Reward: -1504.170
Training steps: 3201 Episode Num: 16 Episode T: 200 Reward: -1544.775
Training steps: 3401 Episode Num: 17 Episode T: 200 Reward: -1058.665
Training steps: 3601 Episode Num: 18 Episode T: 200 Reward: -1049.989
Training steps: 3801 Episode Num: 19 Episode T: 200 Reward: -1510.320
Training steps: 4001 Episode Num: 20 Episode T: 200 Reward: -769.407
Training steps: 4201 Episode Num: 21 Episode T: 200 Reward: -967.380
Training steps: 4401 Episode Num: 22 Episode T: 200 Reward: -746.796
Training steps: 4601 Episode Num: 23 Episode T: 200 Reward: -883.449
Training steps: 4801 Episode Num: 24 Episode T: 200 Reward: -1052.336
Training steps: 5001 Episode Num: 25 Episode T: 200 Reward: -928.282
Training steps: 5201 Episode Num: 26 Episode T: 200 Reward: -894.456
Training steps: 5401 Episode Num: 27 Episode T: 200 Reward: -998.303
Training steps: 5601 Episode Num: 28 Episode T: 200 Reward: -1057.374
Training steps: 5801 Episode Num: 29 Episode T: 200 Reward: -1272.277
Training steps: 6001 Episode Num: 30 Episode T: 200 Reward: -1205.441
Training steps: 6201 Episode Num: 31 Episode T: 200 Reward: -1299.309
Training steps: 6401 Episode Num: 32 Episode T: 200 Reward: -1217.688
Training steps: 6601 Episode Num: 33 Episode T: 200 Reward: -1420.201
Training steps: 6801 Episode Num: 34 Episode T: 200 Reward: -1363.209
Training steps: 7001 Episode Num: 35 Episode T: 200 Reward: -1508.310
Training steps: 7201 Episode Num: 36 Episode T: 200 Reward: -1370.009
Training steps: 7401 Episode Num: 37 Episode T: 200 Reward: -1330.049
Training steps: 7601 Episode Num: 38 Episode T: 200 Reward: -1383.847
Training steps: 7801 Episode Num: 39 Episode T: 200 Reward: -1038.992
Training steps: 8001 Episode Num: 40 Episode T: 200 Reward: -1195.414
Training steps: 8201 Episode Num: 41 Episode T: 200 Reward: -668.078
Training steps: 8401 Episode Num: 42 Episode T: 200 Reward: -908.321
Training steps: 8601 Episode Num: 43 Episode T: 200 Reward: -940.514
Training steps: 8801 Episode Num: 44 Episode T: 200 Reward: -883.374
Training steps: 9001 Episode Num: 45 Episode T: 200 Reward: -868.374
Training steps: 9201 Episode Num: 46 Episode T: 200 Reward: -857.112
Training steps: 9401 Episode Num: 47 Episode T: 200 Reward: -860.965
Training steps: 9601 Episode Num: 48 Episode T: 200 Reward: -754.221
Training steps: 9801 Episode Num: 49 Episode T: 200 Reward: -864.048
Training steps: 10001 Episode Num: 50 Episode T: 200 Reward: -760.417
Training steps: 10201 Episode Num: 51 Episode T: 200 Reward: -870.312
Training steps: 10401 Episode Num: 52 Episode T: 200 Reward: -750.474
Training steps: 10601 Episode Num: 53 Episode T: 200 Reward: -731.629
Traceback (most recent call last):
  File "/gpfs/home1/aiphw227/HRL/code/main.py", line 176, in <module>
  File "/home1/aiphw227/miniconda3/envs/rl/lib/python3.11/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/home1/aiphw227/miniconda3/envs/rl/lib/python3.11/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/home1/aiphw227/miniconda3/envs/rl/lib/python3.11/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/home1/aiphw227/miniconda3/envs/rl/lib/python3.11/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           ^^^^^^
  File "/home1/aiphw227/miniconda3/envs/rl/lib/python3.11/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            ^^^^^^^^^^
  File "/home1/aiphw227/miniconda3/envs/rl/lib/python3.11/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          ^^^^^^^^
  File "/home1/aiphw227/miniconda3/envs/rl/lib/python3.11/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
                       ^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home1/aiphw227/HRL/code/main.py", line 138, in main
    print(
  File "/gpfs/home1/aiphw227/HRL/code/algorithms/ddpg.py", line 64, in train
    state, action, next_state, reward, not_done = replay_buffer.sample(batch_size)
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home1/aiphw227/HRL/code/algorithms/utils/vanilla_buffer.py", line 32, in sample
    torch.FloatTensor(self.state[ind]).to(self.device),
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
